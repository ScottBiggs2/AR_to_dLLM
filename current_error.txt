The following values were not passed to `accelerate launch` and had defaults used instead:
        `--num_machines` was set to a value of `1`
        `--mixed_precision` was set to a value of `'no'`
        `--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2026-01-22:18:38:15,360 INFO     [__main__.py:279] Verbosity set to INFO
2026-01-22:18:38:25,874 WARNING  [__main__.py:312]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2026-01-22:18:38:25,876 INFO     [__main__.py:376] Selected Tasks: ['bbh_cot_fewshot', 'gsm8k', 'minerva_math', 'mmlu_pro']
2026-01-22:18:38:25,887 INFO     [evaluator.py:164] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewsh
ot manual seed to 1234
2026-01-22:18:38:25,887 INFO     [evaluator.py:201] Initializing mdlm model, with arguments: {'pretrained': '/scratch/biggs.s/outputs/qwen3-mdlm-tulu3-sft-v1
/checkpoint-6500', 'max_new_tokens': 512, 'steps': 32, 'block_size': 128}
Traceback (most recent call last):
  File "/home/biggs.s/AR_to_dLLM/AR_to_dLLM/dllm/dllm/pipelines/a2d/eval.py", line 744, in <module>
    cli_evaluate()
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/lm_eval/__main__.py", line 382, in cli_evaluate
    results = evaluator.simple_evaluate(
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/lm_eval/utils.py", line 397, in _wrapper
    return fn(*args, **kwargs)
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/lm_eval/evaluator.py", line 204, in simple_evaluate
    lm = lm_eval.api.registry.get_model(model).create_from_arg_string(
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/lm_eval/api/model.py", line 147, in create_from_arg_string
    return cls(**args, **args2)
  File "/home/biggs.s/AR_to_dLLM/AR_to_dLLM/dllm/dllm/pipelines/a2d/eval.py", line 101, in __init__
    self.model = dllm.utils.get_model(
  File "/home/biggs.s/AR_to_dLLM/AR_to_dLLM/dllm/dllm/utils/models.py", line 81, in get_model
    raise ValueError(f"Could not load model from {model_name_or_path}")
ValueError: Could not load model from /scratch/biggs.s/outputs/qwen3-mdlm-tulu3-sft-v1/checkpoint-6500
Traceback (most recent call last):
  File "/scratch/biggs.s/project_envs/qwen3_dllm/bin/accelerate", line 7, in <module>
    sys.exit(main())
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py", line 50, in main
    args.func(args)
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/accelerate/commands/launch.py", line 1235, in launch_command
    simple_launcher(args)
  File "/scratch/biggs.s/project_envs/qwen3_dllm/lib/python3.10/site-packages/accelerate/commands/launch.py", line 823, in simple_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/scratch/biggs.s/project_envs/qwen3_dllm/bin/python3.10', 'dllm/dllm/pipelines/a2d/eval.py', '--model', 'mdlm', '--
tasks', 'gsm8k,minerva_math,bbh_cot_fewshot,mmlu_pro', '--limit', '-1', '--model_args', 'pretrained=/scratch/biggs.s/outputs/qwen3-mdlm-tulu3-sft-v1/checkpoi
nt-6500,max_new_tokens=512,steps=32,block_size=128', '--apply_chat_template', '--output_path', 'eval_results/checkpoint-6500_20260122_183747']' returned non-
